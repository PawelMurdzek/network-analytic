{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# instalacja paczki związanej z narzędziem do analizy flow wykorzystywanym w dalszej części\n",
        "# wykonanie tej komórki może chwilę potrwać\n",
        "# w zależności od systemu i wersji obecnych paczek, instalacja może być utrudniona ze względu na konieczność rozwiązania różnych zależności\n",
        "# przetestowano dla Google Colab\n",
        "# Uwaga: paczka może mieć ograniczoną kompatybilność z Pythonem w wersji 3.12 - może być potrzeba przejść np. do 3.11\n",
        "\n",
        "!pip install nfstream"
      ],
      "metadata": {
        "id": "KnkGzlfiZJ1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OPbpLLwRrzO"
      },
      "outputs": [],
      "source": [
        "# import potrzebnych bibliotek do środowiska programistycznego (zostaną wykorzystane później)\n",
        "\n",
        "import nfstream\n",
        "from nfstream import NFStreamer\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pobranie i wczytanie danych do programu"
      ],
      "metadata": {
        "id": "W2WxZcbffF_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pobranie próbek z logami z sieci (w normalnym wypadku bralibyśmy je najpewniej gdzieś z naszej sieci)\n",
        "!wget -O normal_traffic.pcap https://mcfp.felk.cvut.cz/publicDatasets/CTU-Normal-13/2017-07-03_capture-win2.pcap\n",
        "!wget -O malicious_traffic.pcap https://mcfp.felk.cvut.cz/publicDatasets/CTU-Malware-Capture-Botnet-14/2013-10-18_capture-win15.pcap\n",
        "\n",
        "\n",
        "# Wczytanie ruchu normalnego\n",
        "normal_streamer = NFStreamer(source=\"normal_traffic.pcap\", statistical_analysis = True)\n",
        "normal_flows = normal_streamer.to_pandas()\n",
        "normal_flows['label'] = 0  # Oznaczenie ruchu jako normalnego\n",
        "\n",
        "# Wczytanie ruchu złośliwego\n",
        "malicious_streamer = NFStreamer(source=\"malicious_traffic.pcap\", statistical_analysis = True)\n",
        "malicious_flows = malicious_streamer.to_pandas()\n",
        "malicious_flows['label'] = 1  # Oznaczenie ruchu jako złośliwego\n",
        "\n",
        "# Połączenie obu zbiorów danych\n",
        "data = pd.concat([normal_flows, malicious_flows], ignore_index=True)\n",
        "\n",
        "# Wyświetlenie pierwszych rekordów zbiorów danych\n",
        "data.head()\n"
      ],
      "metadata": {
        "id": "QA-dZN6wZS-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eksploracja i czyszczenie danych"
      ],
      "metadata": {
        "id": "T-hSwLzjeRxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wyświetlenie podstawowych informacji o zbiorach danych\n",
        "data.info()\n",
        "\n",
        "# Usuwanie kolumn, które mają tylko jedną unikalną wartość lub brakujące wartości\n",
        "for col in data.columns:\n",
        "    if data[col].nunique() == 1 or data[col].isnull().any():\n",
        "        data.drop(col, inplace=True, axis=1)\n",
        "\n",
        "# Wyświetlenie liczby rekordów po czyszczeniu\n",
        "print(f\"Liczba rekordów po czyszczeniu: {data.shape[0]}\")\n"
      ],
      "metadata": {
        "id": "W-kuaFoxbNno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eksperymenty - eksploracja szczegółowa\n",
        "\n",
        "# Wyświetlenie unikalnych wartości w kolumnach (można wybrać kolumnę do analizy)\n",
        "column_name = 'src_ip'  # Przykład nazwy kolumny\n",
        "print(\"Unikalne wartości w kolumnie:\", column_name)\n",
        "print(data[column_name].unique())\n",
        "\n",
        "# Eksploracja liczby rekordów dla każdej etykiety\n",
        "print(\"Liczba rekordów dla każdej etykiety:\")\n",
        "print(data['label'].value_counts())\n",
        "\n",
        "# Histogramy dla wybranych cech numerycznych (należy odkomentować i zmodyfikować)\n",
        "# data['some_numeric_column'].hist(bins=30)\n",
        "# plt.title('Histogram cechy some_numeric_column')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "PHpgDQ7Ge_e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analiza korelacji cech"
      ],
      "metadata": {
        "id": "ZGZzvne_eWJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Wybranie tylko kolumn numerycznych (int i float)\n",
        "data = data.select_dtypes(include=[np.number])\n",
        "\n",
        "# Sprawdzenie, czy kolumna 'label' istnieje w danych\n",
        "if 'label' in data.columns:\n",
        "    # Obliczanie korelacji wszystkich cech z etykietą\n",
        "    correlation_with_label = data.corr()['label'].sort_values(key=abs, ascending=False)\n",
        "\n",
        "    # Usunięcie korelacji etykiety z samą sobą\n",
        "    correlation_with_label = correlation_with_label.drop('label', errors='ignore')\n",
        "\n",
        "    # Wybór 10 najbardziej skorelowanych cech\n",
        "    top_10_correlated_features = correlation_with_label.head(10)\n",
        "\n",
        "    print(\"10 cech najbardziej skorelowanych z etykietą:\\n\", top_10_correlated_features)\n",
        "\n",
        "    # Wizualizacja korelacji tych cech z etykietą\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=top_10_correlated_features.index, y=top_10_correlated_features.values, palette='viridis')\n",
        "    plt.title('Top 10 cech najbardziej skorelowanych z etykietą')\n",
        "    plt.xlabel('Cechy')\n",
        "    plt.ylabel('Współczynnik korelacji')\n",
        "    plt.xticks(rotation=45)  # Obrót etykiet osi X dla lepszej czytelności\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Brak kolumny 'label' w danych.\")\n"
      ],
      "metadata": {
        "id": "7uchTPiTcrAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eksperymenty - analiza wybranych korelacji\n",
        "\n",
        "# Wybór korelacji do szczegółowej analizy (należy odkomentować i zmodyfikować na atrybuty które chcemy sprawdzić)\n",
        "# feature1 = 'source_port'\n",
        "# feature2 = 'destination_port'\n",
        "# sns.scatterplot(x=data[feature1], y=data[feature2])\n",
        "# plt.title(f'Korelacja między {feature1} a {feature2}')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "W6pi0s1cfBZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Przygotowanie danych do modelowania"
      ],
      "metadata": {
        "id": "nd8oBOuMecJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('label', axis=1)\n",
        "y = data['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "OVVEkEq_c_Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Budowanie i trenowanie modelu"
      ],
      "metadata": {
        "id": "OyZdhGTteffw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "def train_and_evaluate_decision_tree(X_train, y_train, X_test, y_test, max_depth=None, criterion='gini'):\n",
        "    # Trenowanie modelu Decision Tree z określonymi parametrami\n",
        "    tree_model = DecisionTreeClassifier(max_depth=max_depth, criterion=criterion, random_state=42)\n",
        "    tree_model.fit(X_train, y_train)\n",
        "\n",
        "    # Przewidywanie na zestawie testowym\n",
        "    predictions = tree_model.predict(X_test)\n",
        "\n",
        "    # Obliczenie metryk\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "    # Wizualizacja drzewa\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plot_tree(tree_model, filled=True, feature_names=X_train.columns, class_names=['Normal', 'Malicious'], fontsize=10)\n",
        "    plt.title(\"Wizualizacja drzewa decyzyjnego\")\n",
        "    plt.show()\n",
        "\n",
        "    return tree_model, accuracy, conf_matrix\n"
      ],
      "metadata": {
        "id": "gRYhnoqnemYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trenowanie i ocena modelu z domyślnymi parametrami\n",
        "default_model, default_accuracy, default_conf_matrix = train_and_evaluate_decision_tree(X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(\"Dokładność modelu z domyślnymi parametrami:\", default_accuracy)\n",
        "sns.heatmap(default_conf_matrix, annot=True, fmt=\"d\")\n",
        "plt.title(\"Macierz błędów - Model domyślny\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OYo-PMrug6z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interaktywne testowanie parametrów modelu"
      ],
      "metadata": {
        "id": "qJI-iqxLeo5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import interactive\n",
        "\n",
        "def interactive_decision_tree_testing(max_depth, criterion):\n",
        "    _, new_accuracy, new_conf_matrix = train_and_evaluate_decision_tree(X_train, y_train, X_test, y_test, max_depth, criterion)\n",
        "\n",
        "    print(\"Dokładność modelu na nowym zestawie danych:\", new_accuracy)\n",
        "    sns.heatmap(new_conf_matrix, annot=True, fmt=\"d\", cmap='viridis')\n",
        "    plt.title(\"Macierz błędów na nowym zestawie danych\")\n",
        "    plt.show()\n",
        "\n",
        "# Stworzenie interaktywnego widgetu do eksperymentowania z parametrami\n",
        "interactive_plot = interactive(interactive_decision_tree_testing,\n",
        "                               max_depth=(1, 20, 1),\n",
        "                               criterion=[\"gini\", \"entropy\"])\n",
        "interactive_plot\n"
      ],
      "metadata": {
        "id": "1RLeBiOLc_Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dla pokazanego przykładu można zaobserwować, że pomimo zwiększania ogranicznenia dotyczącego głębokości drzewa, kontrykcja się już nie zmienia, ponieważ przy niższym poziomie głebokości model przestaje się już kompletnie mylić.\n",
        "\n",
        "**Zadanie:** Zamodeluj bardziej złożoną sytuację dobierając inne zbiory danych, można wybierać z tego samego repozytorium: https://mcfp.felk.cvut.cz/publicDatasets/ (uwaga na rozmiary zbiorów, dla dużych objętności będzie to trwało bardzo długo). W tym celu najlepiej przerabiać kod zaprezentowanny powyżej, albo przeklejać komórki na nowo poniżej i edytować je w nowym miejscu."
      ],
      "metadata": {
        "id": "YpkQumbP2T03"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HyjobzHG2TYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aP1tcScK2f2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bUS4NB6l2f5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Iut46kK2f8U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}